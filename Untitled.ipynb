{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)     # 텐서플로우 버전확인 (colab의 기본버전은 1.15.0) --> 2.0 변경 \"%tensorflow_version 2.x\"\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01  # 러닝레이트 \n",
    "training_epochs = 60 # 에폭\n",
    "batch_size = 32        # 배치사이즈\n",
    "Buffer_size = 100      # 인스턴스 버퍼 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volcano  파일 길이 :  971\n",
      "volcano  :  ./redeepsong/re deepsong/train/volcano\\volcano eruption_original_vo_1.jpg_545ff43d-25a6-4351-a33b-6b9ea6f7e1ef.jpg\n",
      "volcano  :  ./redeepsong/re deepsong/train/volcano\\volcano eruption_original_vo_99.jpg_7ec52b2b-d7e4-47b0-8e5c-fee68432b6e9.jpg\n",
      "earth+mount  파일 길이 :  699\n",
      "earth+mount  :  ./redeepsong/re deepsong/train/earth+mount\\ep285.jpg\n",
      "fire  파일 길이 :  709\n",
      "fire  :  ./redeepsong/re deepsong/train/fire\\fire.245.png\n",
      "fire  :  ./redeepsong/re deepsong/train/fire\\fire_images_original_fire.850.jpg_627826aa-9dca-40df-8444-5e50c0c0bbe2.jpg\n",
      "heavysnow  파일 길이 :  700\n",
      "heavysnow  :  ./redeepsong/re deepsong/train/heavysnow\\heavy snow_original_hv_1.jpg_46750ccf-2fe7-4154-8b4d-145532fe9092.jpg\n",
      "city  파일 길이 :  705\n",
      "city  :  ./redeepsong/re deepsong/train/city\\city301.jpg\n",
      "city  :  ./redeepsong/re deepsong/train/city\\train_original_city698.jpg_169386f5-1b56-4dea-9ce6-bb9d7a25b9dc.jpg\n",
      "nature  파일 길이 :  698\n",
      "nature  :  ./redeepsong/re deepsong/train/nature\\00000206 (5).jpg\n",
      "ok 4482\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "\n",
    "caltech_dir = './redeepsong/re deepsong/train'\n",
    "categories = [\"volcano\", \"earth+mount\", \"fire\", \"heavysnow\", \"city\", \"nature\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 256\n",
    "image_h = 256\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for idx, name in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + name\n",
    "    files = glob.glob(image_dir+\"/*.*\")\n",
    "    print(name, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        x.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(name, \" : \", f)\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3585, 256, 256, 3) (3585, 6)\n",
      "(897, 256, 256, 3) (897, 6)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train set, Test set으로 나누기 (80:20으로 나누기)\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(x, y,train_size=0.8, test_size=0.2, random_state=1,shuffle=True)\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "train_images = train_images.astype('float32')\n",
    "train_images = train_images / 255\n",
    "\n",
    "val_images = val_images.astype('float32')\n",
    "val_images = val_images / 255\n",
    "\n",
    "print(np.shape(train_images), np.shape(train_labels))\n",
    "print(np.shape(val_images), np.shape(val_labels))\n",
    "\n",
    "# dataset 인스턴스 만들기\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(Buffer_size).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential() # Sequential 모델 시작\n",
    "    model.add(keras.layers.Conv2D(filters=48, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME', \n",
    "                                  input_shape=(256, 256, 3)))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=54, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=60, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=66, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=72, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Conv2D(filters=80, kernel_size=3, strides=1, activation=tf.nn.relu, padding='SAME'))\n",
    "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(6, activation=tf.nn.softmax))   #  Dense층\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 48)      1344      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 128, 128, 48)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 54)      23382     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 64, 64, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 60)        29220     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 32, 32, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 66)        35706     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 66)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 72)        42840     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 72)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 80)          51920     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 579,682\n",
      "Trainable params: 579,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model() # 모델 함수를 model로 변경\n",
    "model.summary() # 모델에 대한 요약 출력해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3585 samples, validate on 897 samples\n",
      "Epoch 1/40\n",
      "  32/3585 [..............................] - ETA: 1:51"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n\n    TypeError: tf__initialize_variables() missing 1 required positional argument: 'self'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-e7dd0185a00e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[1;33m,\u001b[0m                     \u001b[1;31m# 1000회 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                  \u001b[1;31m# verbose는 학습 중 출력되는 문구를 설정하는 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m           validation_data=(val_images, val_labels)) # test를 val로 사용\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;34m'validation_steps'\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mspecified\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0monly\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbeginning\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[0mthe\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0mat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mensures\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0mare\u001b[0m \u001b[0mused\u001b[0m \u001b[0mevery\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOnly\u001b[0m \u001b[0mrelevant\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mprovided\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mInteger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtraining_data_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mrecreate_training_iterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               if (training_data_iter is not None and\n\u001b[1;32m--> 324\u001b[1;33m                   distribution_strategy_context.has_strategy()):\n\u001b[0m\u001b[0;32m    325\u001b[0m                 \u001b[1;31m# TODO(kaftan): remove this when MultiDeviceIterator is a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;31m## compositetensor (unless this is more efficient)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m       \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[0mcurrent_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     with training_context.on_batch(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m     85\u001b[0m         per_replica_function, args=args)\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n\u001b[0;32m     88\u001b[0m         strategy, outputs, mode)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m     return function_lib.defun_with_attributes(\n\u001b[0;32m    456\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0minput_signature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0mautograph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autograph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[0minput_signature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_signature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mautograph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autograph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[0mexperimental_implements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_implements\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mexperimental_autograph_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_autograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize_uninitialized_variables\u001b[1;34m(self, initializer_map)\u001b[0m\n\u001b[0;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m       \u001b[1;31m# interestingly an exception was raised) so we no longer need a lock.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1889\u001b[0m       \u001b[1;31m# Either there's a persistent tape watching, or there are multiple nested\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m       \u001b[1;31m# tapes. Either way, the user may request higher-order gradients. We'll\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m       \u001b[1;31m# spend a bit more time and make sure higher-order gradients are correct.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m       functions = self._higher_order_tape_functions.get(\n\u001b[0;32m   1893\u001b[0m           cache_key, None)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Not enough arguments (%s, %s, %s)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m                                                           self.arg_names)\n\u001b[1;32m-> 2150\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdefault_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arg_indices_to_default_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m       \u001b[1;31m# TODO(b/127938157): Should this error out if there is no arg to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m       \u001b[1;31m# be removed?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m       \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullargspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2042\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m       \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullargspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;31m# them. Reassigned below.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     func_graph.inputs = [arg for arg in flat_func_args + flat_func_kwargs\n\u001b[1;32m--> 915\u001b[1;33m                          if isinstance(arg, ops.Tensor)]\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[1;31m# Note: `nest.flatten` sorts by keys, as does `_deterministic_dict_values`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;31m# If storing pure concrete functions that are not called through polymorphic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m     \u001b[1;31m# functions, we don't have access to FunctionSpec, so we need to call the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m     \u001b[1;31m# TensorSpecs by their `arg_names` for later binding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m     func_graph.structured_input_signature = (\n\u001b[0;32m    907\u001b[0m         \u001b[0mconvert_structure_to_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n\n    TypeError: tf__initialize_variables() missing 1 required positional argument: 'self'\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'Adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# 학습실행\n",
    "history = model.fit(train_images, train_labels,       # 입력값\n",
    "          batch_size=batch_size,                      # 1회마다 배치마다 100개 프로세스 \n",
    "          epochs=training_epochs,                     # 1000회 학습\n",
    "          verbose=1,                                  # verbose는 학습 중 출력되는 문구를 설정하는 것 \n",
    "          validation_data=(val_images, val_labels)) # test를 val로 사용\n",
    "\n",
    "\n",
    "# test 값 결과 확인\n",
    "score = model.evaluate(val_images, val_labels, verbose=0) # verbose가 0 이면 ==== 움직이지 않고, 1이면 ==== 진행 바가 움직임\n",
    "print('VAl loss :', score[0])\n",
    "print('VAl ACCURACY :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-be3fd8ef2e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 모델 학습 후 정보가 담긴 history 내용을 토대로 선 그래프를 그리는 함수 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 모델 학습 후 정보가 담긴 history 내용을 토대로 선 그래프를 그리는 함수 설정\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None):     # Loss Visualization\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss'])           # loss\n",
    "    plt.plot(history['val_loss'])       # validation\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "def plot_accuracy(history, title=None):     # Loss Visualization\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['accuracy'])           # loss\n",
    "    plt.plot(history['val_accuracy'])       # validation\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c5e6114b16d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'(a) Loss'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 학습 경과에 따른 정확도 변화 추이\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'(b)) Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization\n",
    "plot_loss(history, '(a) Loss')  # 학습 경과에 따른 정확도 변화 추이\n",
    "plt.show()\n",
    "plot_accuracy(history, '(b)) Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5d649e913bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'deepsong_modelfit_y1.h5'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 모델 아키텍처와 모델 가중치 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('deepsong_modelfit_y1.h5') # 모델 아키텍처와 모델 가중치 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: deepsong_modelfit_y1.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-43799589cb83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'deepsong_modelfit_y1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m     \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     81\u001b[0m                   (export_dir,\n\u001b[0;32m     82\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: deepsong_modelfit_y1.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('deepsong_modelfit_y1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './re deepsong/redeepsong/test'\n",
    "categories = [\"volcano\", \"earth+mount\", \"fire\", \"heavysnow\", \"city\", \"nature\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 256\n",
    "image_h = 256\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "test_image = []\n",
    "test_label = []\n",
    "\n",
    "for idx, name in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = test_dir + \"/\" + name\n",
    "    files = glob.glob(image_dir+\"/*.*\")\n",
    "    print(name, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        test_image.append(data)\n",
    "        test_label.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(name, \" : \", f)\n",
    "\n",
    "test_image = np.array(test_image,dtype=np.float32)\n",
    "test_image = test_image / 255\n",
    "\n",
    "test_image = np.array(test_image)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.imshow(test_image[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_image)\n",
    "print(test_label[0], pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.evaluate(test_image, test_label, verbose=0)\n",
    "\n",
    "print('loss :', test[0])\n",
    "print('ACCURACY :', test[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
